\chapter*{Kurzfassung} 

In Haushaltsumgebungen eingesetzte autonome Roboter müssen in der Lage sein, mit den durch den Menschen verursachten nichtdeterministischen Veränderungen umgehen zu können. Für viele Aufgaben ist es vonnöten, Objekte wahrzunehmen und ihnen aus bekanntem Wissen eine Bedeutung zu geben. Als Grundlage dient dazu eine Perzeptionskomponente, mit der die Umgebungen wahrgenommen und durch Segmentierung Objekte gefunden werden können. Um die Objekte zu interpretieren, ihnen eine Bedeutung zu geben, wird über eine Wissensbasis geschlussfolgert. Wissensbasen müssen vorher jedoch mit Beispielen, den sogenannten Trainingsdaten, trainiert werden. Da die Wissensbasis für die Wahrnehmung verwendet wird, handelt es sich bei den Trainingsdaten um Bilder von möglichen wahrnehmbaren Szenen. Das Trainieren einer Wissensbasis ist jedoch mit hohem Aufwand verbunden, denn die Bilder müssen manuell erstellt werden, und für komplexe Umgebungen sind in der Regel auch eine große Anzahl vonnöten. Diese Arbeit untersucht, ob der Aufwand verringert werden könnte, indem in einer Game Engine synthetisch erzeugte Bilder zum Training verwendet werden. Dazu werden in der \unreal fotorealistische Virtuelle Szenen erzeugt. Das Perzeptionsframework \robosherlock segmentiert diese und die gewonnenen Informationen werden verwendet, um eine Wissensbasis in Form eines Markov-Logik-Netzwerkes zu trainieren. Zur Evaluation wird die Güte der Objektklassifikation durch das MLN in wahrgenommenen Szenen untersucht. 
