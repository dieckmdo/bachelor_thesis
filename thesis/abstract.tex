\chapter*{Kurzfassung} 

In Haushaltsumgebungen eingesetzte autonome Roboter müssen in der Lage sein, mit den durch den Menschen verursachten nichtdeterministischen Veränderungen umgehen zu können. Für viele Aufgaben ist es vonnöten, Objekte wahrzunehmen und ihnen aus bekanntem Wissen eine Bedeutung zu geben. Als Grundlage dient dazu eine Perzeptionskomponente, mit der die Umgebungen wahrgenommen und durch Segmentierung Objekte gefunden werden können. Objekte stellen dabei eine besondere Herausforderung dar, da sie eine Vielzahl verschiedener visueller Eigenschaften aufweisen. Um die Objekte erfolgreich zu interpretieren, ihnen eine Bedeutung zu geben, müssen diese zusammengeführt werden. Dazu wird über eine Wissensbasis geschlussfolgert. Wissensbasen müssen vorher jedoch mit Beispielen, den sogenannten Trainingsdaten, trainiert werden. Da die Wissensbasis für die Wahrnehmung verwendet wird, handelt es sich bei den Trainingsdaten um Bilder von möglichen wahrnehmbaren Szenen. Das Trainieren einer Wissensbasis ist jedoch mit hohem Aufwand verbunden, denn die Bilder müssen manuell erstellt werden, und für komplexe Umgebungen sind in der Regel auch eine große Anzahl vonnöten. Diese Arbeit untersucht, ob der Aufwand verringert werden könnte, indem in einer Game Engine synthetisch erzeugte Bilder zum Training verwendet werden. Dazu werden in einer virtuellen Realität fotorealistische, virtuelle Szenen erzeugt. Das Perzeptionsframework \robosherlock segmentiert diese und extrahiert Informationen über die verschiedenen Eigenschaften der Objekte. Damit wird eine Wissensbasis in Form eines Markov-Logik-Netzwerkes (MLN), das sich besonders zur Zusammenführung von verschiedenen Informationen eignet, trainiert. Zur Evaluation wird die Güte der Objektklassifikation durch das MLN in wahrgenommenen Szenen untersucht. 
