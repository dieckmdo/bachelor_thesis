\graphicspath{{./images/}}      
\def\CHAPTERONE{./chapters/Chapter-1} 

\chapter{Einleitung}
\label{chap:introduction}
%	\input{\CHAPTERONE /motivation}
Autonome Roboter werden mittlerweile in verschiedenen Umgebungen wie industrieellen Fließbändern oder der Medizin eingesetzt. Aber besonders in einer Gesellschaft, in der die Bevölkerung immer älter wird \cite{peopleGetOlder}, ist die Hilfe durch einen autonomen Roboter im Haushalt eine erstrebenswerte Zukunft. Ob es darum geht, Pancakes \cite{beetzPancake} oder Kekse \cite{bakeBot} zu machen oder Wäsche zu waschen \cite{laundry}, die möglichen Aufgaben sind nahezu unbegrenzt und können das Leben erleichtern. \par

Die für uns teils simpel erscheinenden Aufgaben, wie das Einräumen einen Schranks, sind für einen Roboter schon komplexe Vorgänge. Er muss nicht nur die Objekte, die er einräumen soll, eindeutig identifizieren, sondern diese auch richtig und den äußerlichen Eigenschaften entsprechend greifen. So fasst man beispielsweise eine Packung Mehl anders an als eine Flasche Saft. All das muss der Roboter aus den Informationen, die seine Sensoren und Kameras erfassen, schlussfolgern, um so die eigentliche Aufgabe überhaupt beginnen zu können. \par

Umgebungen, die von Menschen bewohnt werden, sind jedoch starken nichtdeterministischen Veränderungen unterworfen. Es werden Objekte verrückt oder komplett aus dem Raum entfernt, sodass selbst wiederholt auszuführende Aufgaben niemals genau gleich ablaufen. Das erfordert von dem Roboter ein hohes Maß an Robustheit gegenüber Veränderungen seiner Umwelt. Grundlage, um auf Veränderungen reagieren zu können, ist dabei die Wahrnehmung oder Perzeption des Roboters. Über Kameras und Sensoren werden Daten über die Umgebung aufgenommen und dem Roboter so ermöglicht, auf die veränderliche Umgebung zu reagieren und Objekte aufzufinden. \par

Allerdings ist der Roboter nicht in der Lage, aus den rohen Sensor- und Kameradaten Annahmen über Objekte zu machen. Es müssen also spezielle Perzeptionsalgorithmen zum Einsatz kommen, die die Daten verarbeiten und interpretieren. Damit liegen dem Roboter Objekthypothesen über den potenziellen Standort von Objekten vor, sowie zusätzliche Informationen über die einzelnen Objekthypothesen. Mit all diesem Wissen über die Objekte kann der Roboter jedoch nichts anfangen, wenn er nicht eine Möglichkeit besitzt, aus den Informationen abzuleiten, um was für Objekte es sich genau handelt. Dazu werden in einer \gls{kb} die Informationen zusammengeführt und verknüpft. Aus vorliegenden Informationen einer Objekthypothese kann der Roboter nun schlussfolgern, um was für ein Objekt es sich handelt.    \par    

Für das Bestehen des Roboters in der veränderlichen Haushaltsumgebung ist das Schlussfolgern also von zentraler Bedeutung. Um eine \gls{kb} zu Trainieren, müssen hochwertige Beispiele der späteren Aufgabe als Trainingsdaten zur Verfügung stehen und diese in der Regel auch in großer Menge. Das Erstellen dieser Daten ist jedoch Zeit- und Ressourcenintensiv. Im Falle der Wahrnehmung eines Roboters müssten viele echte Szenarien erstellt und Bilder oder Videos davon aufgenommen werden, um diese als Trainingsdaten zu benutzen. \par  
    
Abhilfe könnten hier nun moderne \glspl{gameengine} schaffen. Diese bieten die Möglichkeit, hochwertige fotorealistische Umgebungen in Echtzeit zu rendern. Es ist also möglich, Trainingsdaten in einer virtuellen Realität aufzunehmen und damit den Prozess der Erstellung hochwertiger Daten zu automatisieren. \par  

Ziel dieser Arbeit ist es nun, zu testen, ob man mit Bildern aus einer Game Engine eine \gls{kb} antrainieren kann und das folgende Schlussfolgern über die \gls{kb} zur Klassifikation von Objekten zufriedenstellende Ergebnisse liefert. Das \gls{iai}\footnote{\url{http://ai.uni-bremen.de/}} der Universität Bremen hat die Küche, in der mit einem PR2-Roboter geforscht wird, möglichst realistisch in die Unreal Engine (siehe Kapitel \ref{sec:unrealengine} auf S.\pageref{sec:unrealengine}) übertragen. Hier können nun Szenen erzeugt und dann in ein Robotersystem eingespeist werden. Das vom IAI entwickelte \gls{framework} \robosherlock (siehe Kapitel \ref{sec:robosherlock} auf S.\pageref{sec:robosherlock}) wird dann mittels Perzeptionsalgorithmen Informationen über Objekte aus den Bildern herausziehen. Die Informationen über die Objekte basieren auf der Theorie der Attribut-basierten Objekterkennung (siehe Kapitel \ref{sec:aboi} auf S.\pageref{sec:aboi}). Die Informationen dienen als Trainingsdaten für eine \gls{kb} in Form eines \gls{mlns} (siehe Kapitel \ref{sec:mln} auf S.\pageref{sec:mln}), das die Wahrscheinlichkeitsverteilung für potenziell wahrnehmbare Objekte aufspannt. Daraus können auf Basis von wahrgenommenen Bildern Objekte klassifiziert werden.  

\section{Gliederung der Arbeit}
\label{sec:gliederung}

Im folgenden Kapitel werden die Zielsetzung und Motivation dieser Arbeit umrissen und im Zuge dessen auch existierende Systeme und Ansätze vorgestellt, die sich mit ähnlichen Themen beschäftigen. In Kapitel \ref{chap:software} wird die verwendetet Software und \glspl{mln} vorgestellt. Kapitel \ref{chap:implementation} beschreibt die implementierten Lösungen zum Erstellen von fotorealistischen Trainingsdaten und zur Extraktion von Wissen. Die durchgeführten Experimente werden in Kapitel \ref{chap:experiments} erläutert. Zum Abschluss wird in Kapitel \ref{chap:fazit} das Fazit gezogen und ein Ausblick auf mögliche zukünftige Forschungstätigkeiten gegeben. 

   

