\graphicspath{{./images/}}      
\def\CHAPTERONE{./chapters/Chapter-1} 

\chapter{Einleitung}
\label{chap:introduction}
%	\input{\CHAPTERONE /motivation}
Autonome Roboter werden mittlerwile in verschiedenen Umgebungen wie industrieellen Fließbändern oder der Medizin eingesetzt. Aber besonders in einer Gesellschaft in der die Bevölkerung immer älter wird \cite{peopleGetOlder} ist die Hilfe durch einen autonomen Roboter im Haushalt eine erstrebenswerte Zukunft. Ob es darum geht Pancakes \cite{beetzPancake} oder Kekse \cite{bakeBot} zu machen oder Wäsche zu waschen \cite{laundry}, die möglichen Aufgaben sind nahezu unendlich und können das Leben erleichtern. \par
Die für uns teils simpel erscheinenden Aufgaben, wie das einräumen einen Schranks, sind für einen Roboter schon komplexe Vorgänge. Er muss nicht nur die Objekte, die er einräumen soll, eindeutig identifizieren, sondern diese auch richtig und den äußerlichen Eigenschaften entsprechend greifen. So fässt man eine Packung Mehl anders an als eine Flasche Saft. All das muss der Roboter aus den Informationen, die seine Sensoren und Kameras erfassen, Schlussfolgern, um so die eigentliche Aufgabe, das Einräumen des Schranks, überhaupt beginnen zu können. \par
Umgebungen, die von Menschen bewohnt werden, sind jedoch starken nichtdeterministischen Schwankungen unterworfen. Es werden Objekte verrückt oder komplett aus dem Raum entfernt, sodass selbst wiederholt auszuführende Aufgaben niemals genau gleich ablaufen. Das erfordert von dem Roboter ein hohes Maß an Robustheit gegenüber Veränderungen seiner Umwelt. Grundlage um auf Veränderungen reagieren zu können ist dabei die Wahrnehmung oder Perzeption des Roboters. Über Kameras und Sensoren werden Daten über die Umgebung aufgenommen und dem Roboter so ermöglicht die Objekte aufzufinden. \par 
Allerdings kann der Roboter aus den rohen Sensor- und Kameradaten keine Annahme darüber machen, wo sich überhaupt Objekte befinden. Es müssen also spezielle Perzeptionsalgorithmen zum Einsatz kommen, die die Daten verarbeiten und interpretieren. So liegen dem Roboter Objekthypothesen über den potenziellen Standort von Objekten vor, sowie Informationen über die einzelnen Objekthypothesen. Mit all diesem Wissen über die Objekte kann der Roboter jedoch nichts anfangen, wenn er nicht eine Möglichkeit besitzt aus den Informationen abzuleiten, um was für Objekte es sich genau handelt. Dazu werden in einer \gls{kb} die Informationen zusammengeführt und verknüpft, sodass der Roboter aus bestimmten Informationen über eine Objekthypothese schlussfolgern kann, um welches Objekt es sich handelt.    \par    
Für das Bestehen des Roboters in der veränderlichen Haushaltsumgebung ist das Schlussfolgern also von zentraler Bedeutung. Um eine \gls{kb} zu Trainieren müssen hochwertige Beispiele der späteren Aufgabe als Trainingsdaten zur Verfügung zu stehen und diese in der Regel auch in großer Menge. Das Erstellen dieser Daten ist jedoch Zeit- und Ressourcenintensiv. Im Falle der Wahrnehmung eines Roboters müssten viele echte Szenarien erstellt und Bilder davon aufgenommen werden, um diese als Trainingsdaten zu benutzen. \par      
Abhilfe könnten hier nun moderne \glspl{gameengine} schaffen. Diese bieten die Möglichkeit hochwertige fotorealistische Umgebungen in Echtzeit zu rendern. Es bietet sich also die Möglichkeit Trainingsdaten in der virtuellen Realität aufzunehmen und damit den Prozess der Erstellung hochwertiger Daten zu automatisieren. \par  
Ziel dieser Arbeit ist es nun, zu testen, ob man mit Bildern aus einer Game Engine, eine \gls{kb} antrainieren kann und das folgende Schlussfolgern mit der \gls{kb} Ergebnisse liefert, die mit einer mit echten Bilden trainierten \gls{kb} vergleichbar sind. Das \gls{iai}\footnote{\url{http://ai.uni-bremen.de/}} der Universität Bremen hat die Küche, in der mit einem PR2-Roboter geforscht wird, möglichst realistisch in die Unreal Engine (siehe Kapitel \ref{sec:unrealengine} auf S.\pageref{sec:unrealengine}) übertragen. Hier können nun Szenen erzeugt und dann in ein Robotersystem eingespeist werden. Das vom IAI entwickelte \gls{framework} \robosherlock (siehe Kapitel \ref{sec:robosherlock} auf S.\pageref{sec:robosherlock}), wird dann mittels Perzeptionsalgorithmen Informationen über Objekte aus den Bildern herausziehen. Die Informationen über die Objekte basieren auf der Theorie der Attribut-basierten Objekterkennung (siehe Kapitel \ref{sec:aboi} auf S.\pageref{sec:aboi}). Die Informationen dienen als Trainingsdaten für eine \gls{kb} in Form eines \gls{mlns} (siehe Kapitel \ref{sec:mln} auf S.\pageref{sec:mln}), aus dem auf Basis von wahrgenommenen Bildern Objekthypothesen  geschlussfolgert werden können.  

\section{Gliederung der Arbeit}
\label{sec:gliederung}

Im folgenden Kapitel werden die Zielsetzung und Motivation dieser Arbeit umrissen und im Zuge dessen auch existierende Systeme und Ansätze vorgestellt, die sich mit ähnlichen Themen beschäftigen. In Kapitel \ref{chap:software} wird die verwendetet Software und \glspl{mln} vorgestellt. Kapitel \ref{chap:implementation} beschreibt die implementierten Lösungen zum Erstellen von fotorealistischen Trainingsdaten und zur Extraktion von Wissen. Die durchgeführten Experimente werden in Kapitel \ref{chap:experiments} erläutert. 
\todo{vervollständigen}

   

