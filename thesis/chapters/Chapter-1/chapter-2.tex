\graphicspath{{./images/}}      
\def\CHAPTERONE{./chapters/Chapter-1} 

\chapter{Zielsetzung und Motivation}
\label{chap:motivation}
%	\input{\CHAPTERONE /motivation}

% Sinn und Zweck der Arbeit
% Was ist das Ziel? Was will ich herausfinden?
% Warum ist diese Arbeit sinnvoll?
% Was kann mit den Ergebnissen erreicht werden?

Von Menschen bewohnte Umgebungen, wie eine Küche, sind starken nichtdeterministischen Veränderungen unterworfen. Den einen morgen werden Cornflakes gegessen, den nächsten ein Knuspermüsli. Eine Packung Eistee wird nach dem benutzen nicht wieder zurück an den selben Ort gestellt. Ein autonomer Roboter der in einer solchen Haushaltsumgebung operieren soll, muss mit der Fähigkeit ausgestattet sein, die Szenerie, die sich ihm offenbart zu interpretieren. Genauer gesagt, muss er Objekte in einer solchen Szene identifizieren können, um die ihm gestellte Aufgabe zu bewältigen. Soll er die Müsli Packung wieder wegräumen, muss er erst einmal herausfinden, wo sie sich jetzt auf dem Tisch befindet, und auch erkennen, um welche Packung es sich handelt, um sie wieder an ihren richtigen Platz zu stellen.  Dabei greift der Roboter auf eine Form einer \gls{kb} zurück, um die Objekte auf Grundlage seiner Wahrnehmungssysteme zu identifizieren. Die beiden Müsli Packungen sind beide Box-artig, jedoch unterscheidet sich die Cornflakes Packung in ihrer gelben Farbe von der grünen Knuspermüsli Packung. Mit dem Wissen aus der \gls{kb}, kann der Roboter nun schlussfolgern, dass die noch dort stehende Packung eine Cornflakes Packung ist. ein Das Trainieren solcher \glspl{kb} ist jedoch aufwendig, da eine große Menge an Trainingsdaten für gute Resultate zur Verfügung stehen muss beziehungsweise erstellt werden müssen. Also zum Beispiel Szenen in denen verschiedene Müsli Packungen an verschiedene Orten gepaart mit verschiedenen Schüsseln und Milchsorten stehen. So können die Unterschiede besser herausgearbeitet und die einzelnen Objekte und ihre Zusammenhänge besser erlernt werden. Das Erstellen künstlicher Trainingsdaten könnte diesen Prozess vereinfachen. Für optimale Ergebnisse sollten die künstlichen Trainingsdaten eine möglichst große Ähnlichkeit mit der echten Umgebung aufweisen, damit er nicht zu Verwirrung und Fehlern bei der Klassifizierung kommt. Eine künstliche Cornflakes Packung sollte also die gleichen Eingenschaften, also zum Beispiel eine gelbe Textur und eine box-artige Form, aufweisen, wie die echte Packung. Virtuelle Realität ist in der Lage fotorealistische Szenen zu schaffen und könnte damit ein gutes Mittel sein, künstliche Trainingsdaten zu erstellen.  

\section{Perzeption}
In der Robotik beschreibt die Perzeption die Wahrnehmung des Roboters. Damit sich ein Roboter in einer Umgebung überhaupt zurechtzufinden kann, ist sie unerlässlich. Am häufigsten werden \gls{rgb}-Kamerabilder als Eingabe benutzt, um darauf Perzeptionsalgorithmen laufen zu lassen, die Objekte in den wahrgenommen Szenen zu finden und zu erkennen versuchen. Im folgenden werden einige Systeme und Ansätze dazu vorgestellt.

\subsection{Systeme zur Objekterkennung}

In \cite{multimodalTemplate} werden Objekte durch \textit{Template-Matching} identifiziert. Template-Matching beschreibt dabei den Abgleich des Wahrgenommen Objektes mit gespeicherten Vorlagen und darin gespeicherten Hinweisen. Im Gegensatz zum simplen Template-Matching werden im LINE-MOD Algorithmus aus \cite{multimodalTemplate} mehrere Modalitäten/Informationen aus verschiedenen Quellen in den Vorlagen gespeichert. Aus Farbbildern kann der Frabgradient als Hinweis und aus dem Tiefenbild können die Normalen der Oberfläche gewonnen werden. Im Gegensatz zu traditionellen Lernverfahren für \glspl{kb} ist das extrahieren der Hinweise und das anlegen einer Vorlage schnell gemacht. Durch die Hinweise aus verschiedenen Quellen wird auch eine hohe Robustheit und Erkennungsrate erreicht, da sie sich gegenseitig ergänzen und so Hintergrundstördaten weniger ins Gewicht fallen. \par


\cite{moped} \newline
framework zur Objekterkennung. Veruscht in Szenen mit hoher Komplexität zu arbeiten und mit geringer Latenz. \newline
Erreicht mit ICE(Iterative Clustering-Estimation): schätzt Featuregruppen (via SIFT, keypoints) ab, die wahrscheinlich zu Objekt gehören. SUcht Objekt-Hypothesen darin. Damit dann verbesserung der FeatGruppe und damit Hypo (``ICE iteratively executes clustering and pose estimation to progressively rene which features belong to each object instance, and to compute the object poses that best each object instance.'')... Einfache Paralellisierung möglich (Latenz bewältigen) \newline
Projection Clustering (Pose clustering algorithm): da Hypothesen von noisy Kamerabilder: Ausreißer! Jeder Typ wird ausgewertet und falsche Hypos mit den wahrscheinlich richtigen vereinigt. \newline
Ziel MOPED: Input:Bilder u DB. Output: Erkennung u Pose Estiamtion von Objekten. \newline
Learning der DB über 3D Modelle, die durch verschiedene Viewpoint Bilder der Objekte erstellt werden. \newline
Per image: 1 featExtraction, 1 matching, iter ICE ( 2 times), final cluster merging to merge not yet merged double detections. \newline
Medel creation braucht menschliche Interaktion. \par


\cite{3dnet} \newline
3DNet: DB mit 3D-CAD Modellen. + Framework: basiert auf PCL. bietet Deskriptoren, die mit 3D-Modellen traniiert werden und so echtzeit Objekt- und Objektklassen klassifizierung und Pose recognition bieten. In ROS integrierbar. Kinect Bilder zur Klassifikation. \newline
Objektklassen über Link zu WordNet. \newline 
Training mit 3D Modellen bietet Vorteile: 
\begin{itemize}
	\item Completeness
	\item Parameterizable
	\item sensor independence
	\item additional info available
\end{itemize}
Parameter und Deskriptoren Gewichtung Lernen ohne echte Szenen \newline
Intention von 3DNet: quelloffenes Framework mit TestDBs für Benchmarking zum objektiven Vergleich von Shape-Deskriptoren. \par


\citep{modelsWWW}
Lernen der Objekte von CAD-Modellen aus dem WWW. \newline
Detektion von Objekten durch Parts. (Lehne, Beine, ...) Besser bei Okklusion und verschiedenen Viewpoints. Mtching der Parts und Hough Voting, was das sein könnte. Dann welches CAD-Modell passt bestend? \newline
Lernen mit nur einem Modell pro Objekt, da andere ANsichten vom Roboter generiert werden können. Mit simuliertem Laserscan des Roboters über CAD-Modell um so Point CLoud zu kriegen.\newline
Repräsentation der Modelle: Vokabular der Parts + räumliche Anordnung in spezifischen Training Objekten. \newline
WWW hat gute CAD-Modelle von Büromöbeln (wg. Hobby, Hersteller). Experimente mit Büromöbeln. Sensor nimmt Point Cloud auf. \newline
Roboter in der Lage unbekannte Möbel zu erkennen und kategorisieren. \par


\cite{3DCNNObjRec} \newline
3D Objekterkennung in echten 2D-Bildern mit CNN-Model trainiert auf 3D-Modellen. \newline
Synthetische Erstellung von Trainingdaten mit 3D-Modellen und verschieden Viewpoints. \newline
Feature-based objet recognition \newline
Hohe Erkennrate (besser als MOPED). Nur wenn akkurate 3D-Modelle vorhanden und ein 3D-Model für eine Objektinstanz.


\cite{synthImg} \newline
Kleine Menge echter Bilder als Seed, um daraus synthetische Blder zu gernerieren, mit denen ein Klassifizierer trainiert wird. \newline
Nicht ganz deatiltreue 3D-Modelle. Diese werden in Background eingefügt + automatisch ausgewähltes postprocessing (MotionBlur, Noise, etc), um dem echten Bild möglichst nahe zu kommen. Dann Position + Orientierung des Objekts veränderbar, um so viele synthetische Bilder zu kriegen. \newline
Gleichheit mit Funktion: wichitger, was fürs Training wichtig als größte Gleichheit. Also Gleicheit abhängig von features die classifier bei Detektion benutzt. \newline
12 real seed Bilder reichen, um genug syn Bilder zu erzeugen, um einen classifier zu outperformen der mit $>=12*8$ realen Bildern gemacht. \newline
Gute Ergebnisse. Outperformence von classifier nur mit Real Bildern traniert. 

\subsection{Attribut-basierte Objekt Erkennung}
\label{sec:aboi}

\cite{descObjbyAtr} \newline
Attribute von bekannten und unbekannten Objekten, um diese zu beschreiben, vergleichen und kategorisieren. Generalisierung von Kategorien einfacher mit Attributen. Attributklassifizierer nur mit features trainieren, die für das Attribut relevant sind (Farbe unwichitg für Form). Vermeidung von lernen des Korrelierenden Attributes. (wheel with Cars ->learn metallic. Wodden carriages??)\newline
Beschreibe unbekannte Objekte und lerne schnell Dinge über sie. \newline 
Semantische Attribute (Form, Material) nicht immer genug, also auch UnterscheidungsAttribute (Katzen und Hunde haben es, Pferde nicht).\newline
Mehrere Objekte teilen sich Attribute. Deshalb Verwendung von vorhergesehenen Attributen als features = kompakter, weniger features insgesamt. Damit nicht nur Erkennung sondern auch Unbekanntes beschreibbar. Fehlen oder Vorhandensein atypischer Attribute aufzeigbar. Modellernen mit wenig Beispielen und neue Kategorien auch aus Text allein ohne Bilder. \newline
Zeigt: \textit{selected feature} lernen (bei wheel, Bilder mit wheel und ohne, um lernen von metallic zu vermeiden) verbessert Klassifizierung (cross Category generalization). Mit allen feats scheint zu verwirren aka Traning set Korrelation bias. \newline
image features zu Kategorie bei Unbekannten hilflos. Also Attribute benutzen. So nicht nur Name sondern Eigenschaften benennbar.

\par

\cite{atrBasedObjIden} \newline
Identifizierung von Objekten basierend auf Aussehen und Namen Eigenschaften. \newline
Idnetifiziere Objekt in in Szene mit segmentierten Objekten basierend auf einem Satz, der Objekt beschreibt. \newline
110 Objekte in 12 Kategorien. \newline
Zeigt, dass Kombination verschiedener Attributklassifizierer die einzelnen Outperformed. Allerdings bei vielen Objekten nicht so gut. Man sollte örtliche oder relative(dunkler, kleiner) Beschreibungen zulassen. Bei Test mit minimalem subset der Attribute (nur Attribute um Objekte auseinander zu halten) zeigt hohe Robustheit von ABOI.
``We believe that the capability to learn from smaller sets
of examples will be particularly important in the context of
teaching robots about objects and attributes.'' \par


\cite{pronobis1} \newline
Zusammenführung von verschiedenen Informationsquellen mit verschiedenem Datentypen (Aussehen und Geometrie von Orten, Objekt informationen, Topologische Struktur, mensch Input). Kern: kompakte Repräsentation von komplexem, dynamischen, räumlichen Wissen. \newline
Kompakt: robuster mit Dynamik. \newline
Infer zusaätzliches Wissen aus Wissen + Sehen. \newline
KB in 4 Layers, categorical Layer hat Modelle von Objekten, Landmarks, room shapes. \newline
conceptual layer: Common-sense conceptual knowledge + Taxonomy von räumlichen Konzepten. Hier Info, dass kÜche enthält Milch und durch inferenz: sehe Milch also bin wahrscheinlich in Küche. Darstellung in realtionalen Beziehungen(kitchen has-object milk) und Instance-Wissen (obj1 is-a milk, place1 has-object obj1).\newline
Properties of Space: Ort bekommt Attribute, um ihn zu beschreiben.(objects, size, shape) \newline
Conceptual Map (KB): chain graph. Erlaubt reasoning über unbekannte Räume




\todo{PR2 Loóking at Things}



\section{Virtuelle Realität}

Wchitg für was soll cih tun? Was ist das? Kenne ich das schon.

Paar Algorithmen, Grundlagen, Trends (PRM) 

\section{MLN oder sowas}

\section{Ziel der Arbeit}
\label{sec:goal}

Untersuche ob die Perzeption an diesen Daten und das Reasoning über ein KB mit den Daten gute Ergebnisse liefert. Dann automatisierung von Testdaten ersteelung möglich. 