\graphicspath{{./images/}}      
\def\CHAPTERONE{./chapters/Chapter-1} 

\chapter{Zielsetzung und Motivation}
\label{chap:motivation}
%	\input{\CHAPTERONE /motivation}

% Sinn und Zweck der Arbeit
% Was ist das Ziel? Was will ich herausfinden?
% Warum ist diese Arbeit sinnvoll?
% Was kann mit den Ergebnissen erreicht werden?

Von Menschen bewohnte Umgebungen, wie eine Küche, sind starken nichtdeterministischen Veränderungen unterworfen. Den einen morgen werden Cornflakes gegessen, den nächsten ein Knuspermüsli. Eine Packung Eistee wird nach dem benutzen nicht wieder zurück an den selben Ort gestellt. Ein autonomer Roboter der in einer solchen Haushaltsumgebung operieren soll, muss mit der Fähigkeit ausgestattet sein, die Szenerie, die sich ihm offenbart zu interpretieren. Genauer gesagt, muss er Objekte in einer solchen Szene identifizieren können, um die ihm gestellte Aufgabe zu bewältigen. Soll er die Müsli Packung wieder wegräumen, muss er erst einmal herausfinden, wo sie sich jetzt auf dem Tisch befindet, und auch erkennen, um welche Packung es sich handelt, um sie wieder an ihren richtigen Platz zu stellen.  Dabei greift der Roboter auf eine Form einer \gls{kb} zurück, um die Objekte auf Grundlage seiner Wahrnehmungssysteme zu identifizieren. Die beiden Müsli Packungen sind beide Box-artig, jedoch unterscheidet sich die Cornflakes Packung in ihrer gelben Farbe von der grünen Knuspermüsli Packung. Mit dem Wissen aus der \gls{kb}, kann der Roboter nun schlussfolgern, dass die noch dort stehende Packung eine Cornflakes Packung ist. ein Das Trainieren solcher \glspl{kb} ist jedoch aufwendig, da eine große Menge an Trainingsdaten für gute Resultate zur Verfügung stehen muss beziehungsweise erstellt werden müssen. Zum Beispiel Szenen in denen verschiedene Müsli Packungen an verschiedenen Orten gepaart mit verschiedenen Schüsseln und Milchsorten stehen. So können die Unterschiede besser herausgearbeitet und die einzelnen Objekte und ihre Zusammenhänge besser erlernt werden. Das Erstellen künstlicher Trainingsdaten könnte diesen Prozess vereinfachen. Für optimale Ergebnisse sollten die künstlichen Trainingsdaten eine möglichst große Ähnlichkeit mit der echten Umgebung aufweisen, damit er nicht zu Verwirrung und Fehlern bei der Klassifizierung kommt. Eine künstliche Cornflakes Packung sollte also die gleichen Eingenschaften, also zum Beispiel eine gelbe Textur und eine box-artige Form, aufweisen, wie die echte Packung. Virtuelle Realität ist in der Lage fotorealistische Szenen zu schaffen und könnte damit ein gutes Mittel sein, künstliche Trainingsdaten zu erstellen.  

\section{Perzeption}
In der Robotik beschreibt die Perzeption die Wahrnehmung des Roboters. Damit sich ein Roboter in einer Umgebung überhaupt zurechtzufinden kann, ist sie unerlässlich. Am häufigsten werden \gls{rgb}-Kamerabilder als Eingabe benutzt, um darauf Perzeptionsalgorithmen laufen zu lassen, die Objekte in den wahrgenommen Szenen zu finden und zu erkennen versuchen. Im folgenden werden einige Systeme und Ansätze dazu vorgestellt.

\subsection{Systeme zur Objekterkennung}

In \cite{multimodalTemplate} werden Objekte durch \textit{Template-Matching} identifiziert. Template-Matching beschreibt dabei den Abgleich des Wahrgenommen Objektes mit gespeicherten Vorlagen und darin gespeicherten Hinweisen. Im Gegensatz zum simplen Template-Matching werden im LINE-MOD Algorithmus aus \cite{multimodalTemplate} mehrere Modalitäten/Informationen aus verschiedenen Quellen in den Vorlagen gespeichert. Aus Farbbildern kann der Farbgradient als Hinweis und aus dem Tiefenbild können die Normalen der Oberfläche gewonnen werden. Im Gegensatz zu traditionellen Lernverfahren für \glspl{kb} ist das extrahieren der Hinweise und das anlegen einer Vorlage schnell gemacht. Durch die Hinweise aus verschiedenen Quellen wird auch eine hohe Robustheit und Erkennungsrate erreicht, da sie sich gegenseitig ergänzen und so Hintergrundstördaten weniger ins Gewicht fallen. \par

Das MOPED-Framework \cite{moped} versucht Objekterkennung in Szenen mit hoher Komplexität zu realisieren. Dabei wird auf eine Datenbank zurückgegriffen, die 3D-Modelle von Objekten enthält. Diese wurden aus Bildern mit verschiedenen Ansichten der echten Objekte erstellt. Der Vorgang ist allerdings nicht vollautomatisch, sondern braucht menschliche Aufsicht. Wichtiger Bestandteil des MOPED-Frameworks ist das \textit{Iterative Clustering-Estimation (ICE)}. Damit wird versucht, extrahierte Merkmale des Bildes einem Objekt in der Datenbank zuzuordnen und die Pose des Objektes zu ermitteln. Dazu werden Merkmale, die wahrscheinlich zu einem Objekt gehören, zu Gruppen zusammengefasst, und darin nach Objekthypothesen gesucht. Iterativ wird dann geschaut, ob Gruppen basierend auf ihrer Pose zum gleichen Objekt gehören und dann vereinigt. Ein Durchlauf von MOPED wendet dabei mehrere Iterationen von ICE an, was es erlaubt falsche Hypothesen zu erkennen und sie den richtigen zuzuordnen. Die Iterationen können auch einfach parallelisiert werden, wodurch MOPED eine geringere Latenz bei der Online-Erkennung als andere Frameworks aufweist.  \par

Eine bessere Erkennungsrate als MOPED bietet das Verfahren in \cite{3DCNNObjRec}. Hier werden \gls{cnn}-Modelle mit 3D-Modellen von Objekten trainiert, die dann zur Objekterkennung in Bildern benutzt werden. Die Erkennung basiert wie MOPED auch auf Merkmalen. Die 3D-Modelle werden mit Merkmalen angereichert und um ein Trainingsdatenset zu erhalten, werden die sie vor verschiedenen Hintergründen in verschiedenen Posen abgebildet. Bei der Erkennung werden Merkmale aus den 2D-Bildern extrahiert und den 3D-Modellen zugeordnet werden. Damit gute Erkennungsraten erhalten werden, müssen jedoch akkurate 3D-Modelle zur Verfügung stehen und für jede Objektinstanz ein Modell, denn sonst können einzelne Objekte nicht auseinandergehalten werden.   \par

Das 3DNet Framework \cite{3dnet} bietet Objektklassifizierung und Posenerkennung basierend auf einer Datenbank mit 3D-\gls{cad}-Modellen. Dazu werden Deskriptoren mit den \gls{cad}-Modellen trainiert. In Echtzeit können nun Objekte in Bildern der Microsoft Kinect Kamera klassifiziert werden. Das Framework basiert dabei auf der \gls{pcl}\cite{pcl} und lässt sich in \acrshort{ros} integrieren. Außerdem werden einige Vorteile, die das Training mit 3D-Modellen bietet, aufgezeigt:  
\begin{itemize}
	\item Vollständigkeit
	\item Parametrisierbarkeit
	\item Sensoren Unabhängigkeit
	\item Zugriff auf zusätzliche Informationen
\end{itemize}

Im Gegensatz zu \cite{3DCNNObjRec} werden in \cite{synthImg} absichtlich nicht ganz detailgetreue 3D-Modelle benutzt, um mit ihnen synthetische Bilder zum Training eines Klassifizierers zu generieren. Als Grundlage dienen dazu eine kleine Menge echter Bilder von Drohnen. Aus diesen Bildern werden mit den 3D-Modellen der Drohnen möglichst ähnliche synthetische Bilder erzeugt. Dazu werden die Modelle in den Hintergrund eingefügt und auf den Bildern automatisch Postprocessing, wie MotionBlur und Noise, angewandt. Die Ähnlichkeit wird mit einer Funktion gemessen und sollte das synthetische Bilder nach der Funktion eine passende Ähnlichkeit aufweisen, werden aus dem Bild weitere erzeugt, indem die Position und Orientierung des Drohnen-Modells verändert werden. Die eigentliche Klassifizierung basiert wieder auf Merkmalen der Objekte, deshalb sollte das Ziel der Ähnlichkeitsfunktion auch nicht sein, möglichst schöne und echt Bilder zu generieren, sondern Bilder die effektiv für das Training sind. Experimente zeigen das so trainierte Klassifizierer bessere Ergebnisse liefern als mit echten Bildern trainierte Klassifizierer. Vor allem reichen bereits 12 reale Bilder, um genügend synthetische Bilder zu erzeugen, um einen Klassifizierer zu trainieren, der bessere Ergebnisse liefert, als ein mit $\geqq 12 * 8$ realen Bildern trainierter Klassifizierer. \par    

Auch in \citep{modelsWWW} werden 3D-\gls{cad}-Modelle verwendet, um einen Roboter Büromöbel identifizieren zu lassen. Anders als bei den vorherigen Methoden werden allerdings keine kleinen Merkmale betrachtet, sondern die Klassifizierung auf Basis von Objektteilen. Dies sind bei einem Stuhl zum Beispiel Lehne, Beine und Sitzfläche. Dies bietet Vorteile gerade bei starker Okklusion und wenn verschiedene Ansichten vorliegen. Die Modelle werden aus dem World Wide Web bezogen, da Hersteller und Hobbykünstler gute Modelle zur Verfügung stellen. Für ein Möbelstück wird nur ein Modell benötigt, da damit verschiedene Ansichten vom Roboter erstellt werden können, mit denen er dann trainiert wird. Repräsentiert werden die Modelle intern von einem Vokabular der einzelnen Teilstücke sowie einer räumlichen Anordnung innerhalb spezifischer Modelle. Die Klassifizierung findet dann über einen Abgleich der wahrgenommen Teile mit einem Voting, um was für ein Teil es sich handeln könnte, statt, bevor geschaut wird, zu welchem \gls{cad}-Modell die Anordnung der Teile am ehesten passen könnte. So ist der Roboter auch in der Lage unbekannte Möbel als Stuhl oder Tisch zu identifizieren, wenn die charakteristische Anordnungen von Teilstücken übereinstimmt.   

\subsection{Attribut-basierte Objekterkennung}
\label{sec:aboi}

Die Verwendung von Merkmalen in Bildern zur Identifikation von Objekten hat einen entschiedenen Nachteil: Merkmale von unbekannten Objekten können zwar wahrgenommen werden, die Merkmale können auf Grund eines fehlenden Modells oder Referenz in der \gls{kb} jedoch mit keinem Objekt verknüpft werden. Somit kann das unbekannte Objekt auch nicht erkannt werden. \newline
Stattdessen können Attribute benutzt werden, um Objekte zu beschreiben. Diese Attribute können so etwas wie Form, Farbe oder Material sein. Damit können auch unbekannte Objekte beschrieben, und verglichen werden. Auch die Klassifizierung wird vereinfacht: Tassen sind kleine Zylinder mit einem Henkel. Gleichzeitig wird die Repräsentation kompakter und einfacher, da man sich auf Attribute beschränken kann, die für die Aufgabe relevant sind, anstatt alles zu analysieren. In einer Küchenumgebung wird zum Beispiel im Normalfall kein Wissen benötigt, ob Objekte Räder besitzen. Also wird auch kein Algorithmus benötigt, der versucht Räder in der Szene zu finden. Des weiteren bietet die Attribut-basierte Objekterkennung die Möglichkeit Objekte auf Grund des Fehlens oder Vorhandenseins bestimmter Attribute voneinander zu unterscheiden: Tassen und Messbecher haben einen Henkel, Teller nicht. Natürlich kann es auch immer Ausnahmen von der Regel geben, wie einen Messbecher ohne Henkel. \newline
Im Grunde basiert die Attribut-basierte Objekterkennung auf der Art und Weise, wie der Mensch Objekte beschreibt, erkennt und unterscheidet. Bei einem kleinen Zylinder mit Henkel, stellt man sich eine Tasse vor. Und wenn man eine bestimmte Tasse zum ersten Mal sieht, weiß man doch sofort, dass es sich um eine Tasse handelt und wie mit ihr umzugehen ist. Da sich Objekte effektiv mit Attributen beschreiben lassen, können neue Modelle auch aus Beschreibungen, also natürlicher Sprache, gelernt werden. \newline
Beim Trainieren von Klassifizierern für ein Attribut ist jedoch Vorsicht geboten: wird ein Klassifizierer für das Erkennen von Henkeln nur mir Tassen gefüttert, so kann es passieren, dass er stattdessen Zylinder lernt und nicht Henkel. Das ist im Nachhinein schwierig nachzuweisen, denn die Tassen werden trotzdem richtig klassifiziert, kugelähnliche Teekannen allerdings nicht. Um das zu vermeiden sollten beim Training Bilder benutzt werden, die sowohl Henkel haben, als auch nicht. So wird es vermieden, das korrelierende Attribute zu lernen und die Klassifizierung durch \textit{Cross-Kategorie Generalisierung} verbessert. \cite{descObjbyAtr} \par

In \cite{atrBasedObjIden} wird Attribut-basierte Objekterkennung benutzt, um Objekte in einer Szene basierend auf einem Satz zu identifizieren. Die Experimente zeigen, dass eine Kombination verschiedener Attributklassifizierer, bessere Ergebnisse liefert, als die jeweils Einzelnen. Allerdings gibt es bei vielen Objekten Probleme sie richtig einzuordnen, da sie sich zu ähnlich sehen. Dies könnte jedoch durch das Benutzen von zusätzlichen örtlichen oder relativen Beschreibungen, wie \glqq dunkler als\grqq \space oder \glqq kleiner als\grqq, verbessern. Und der Test, nur eine minimale Menge der Attribute, die benötigt werden um die Objekte gerade so auseinanderhalten zu können, zeigt eine hohe Robustheit der Attribut-basierten Objekterkennung. Die Autoren kommen damit zu folgender Aussage, die für die Perzeption von Robotern und das Trainieren von \glspl{kb} von Bedeutung ist: 
\begin{quote}
\glqq We believe that the capability to learn from smaller sets
of examples will be particularly important in the context of
teaching robots about objects and attributes.\grqq \hfill -- \cite{atrBasedObjIden}
\end{quote}

\cite{pronobis1} \newline
Zusammenführung von verschiedenen Informationsquellen mit verschiedenem Datentypen (Aussehen und Geometrie von Orten, Objekt informationen, Topologische Struktur, mensch Input). Kern: kompakte Repräsentation von komplexem, dynamischen, räumlichen Wissen. \newline
Kompakt: robuster mit Dynamik. \newline
Infer zusaätzliches Wissen aus Wissen + Sehen. \newline
KB in 4 Layers, categorical Layer hat Modelle von Objekten, Landmarks, room shapes. \newline
conceptual layer: Common-sense conceptual knowledge + Taxonomy von räumlichen Konzepten. Hier Info, dass kÜche enthält Milch und durch inferenz: sehe Milch also bin wahrscheinlich in Küche. Darstellung in realtionalen Beziehungen(kitchen has-object milk) und Instance-Wissen (obj1 is-a milk, place1 has-object obj1).\newline
Properties of Space: Ort bekommt Attribute, um ihn zu beschreiben.(objects, size, shape) \newline
Conceptual Map (KB): chain graph. Erlaubt reasoning über unbekannte Räume




\todo{PR2 Loóking at Things}



\section{Virtuelle Realität}

Wchitg für was soll cih tun? Was ist das? Kenne ich das schon.

Paar Algorithmen, Grundlagen, Trends (PRM) 

\section{MLN oder sowas}

\section{Ziel der Arbeit}
\label{sec:goal}

\todo{Object Recognitiin mit 3D-Models hat schöne Liste für und gegen 3D-Model Training, vllt hier einflißen lassne.}

Untersuche ob die Perzeption an diesen Daten und das Reasoning über ein KB mit den Daten gute Ergebnisse liefert. Dann automatisierung von Testdaten ersteelung möglich. 